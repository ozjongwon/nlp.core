(ns nlp.core
  (:require
;;   [clojure.data.json :as json]
   [clojure.set :as set]
;;   [loom.attr :as attr]
;;   [loom.graph :as graph]
   )
  (:import (java.io StringReader)
           (java.util ArrayList
                      Collection
                      Map
                      Properties)
           (edu.stanford.nlp.process DocumentPreprocessor
                                     PTBTokenizer)
           (edu.stanford.nlp.ling CoreLabel TaggedWord Word)
           (edu.stanford.nlp.tagger.maxent MaxentTagger)
           (edu.stanford.nlp.trees LabeledScoredTreeNode
                                   LabeledScoredTreeReaderFactory
                                   PennTreebankLanguagePack
                                   TypedDependency)
           (edu.stanford.nlp.parser.common ParserGrammar)
           (edu.stanford.nlp.parser.lexparser LexicalizedParser)
           (edu.stanford.nlp.pipeline Annotation StanfordCoreNLP)
           (edu.stanford.nlp.ling CoreAnnotations$SentencesAnnotation
                                  CoreAnnotations$TextAnnotation
                                  CoreAnnotations$NamedEntityTagAnnotation
                                  CoreAnnotations$TokensAnnotation
                                  Word))
  (:gen-class :main true))

(defn make-print-method [obj]
  (let [resolved-obj (resolve obj)
        str-prefix (str "#<"  (.getSimpleName resolved-obj) " ")]
    `(defmethod print-method ~resolved-obj
       [piece# ^java.io.Writer writer#]
       (.write writer#
               (str ~str-prefix (.toString piece#) ">")))))

(defmacro def-print-methods [& objects]
  (let [qualified-objs objects]
    `(do ~@(map (fn [obj]
                  (make-print-method obj)) qualified-objs))))

(def-print-methods CoreLabel TaggedWord Word)

(defn- tokenize-corelabels [text]
  "Tokenize an input string into a sequence of CoreLabel objects"
  (.tokenize
    (PTBTokenizer/newPTBTokenizer
      (StringReader. text) false false)))


(defn tokenize [text]
  (mapv #(array-map :token (.get % CoreAnnotations$TextAnnotation)
                    :start-offset (.beginPosition %)
                    :end-offset (.endPosition %))
        (tokenize-corelabels text)))

(defn split-sentences [text]
  "Split a string into a sequence of sentences, each of which is a sequence of CoreLabels"
  (->> (StringReader. text)
       (DocumentPreprocessor.)
       (.iterator)
       (iterator-seq)))


(defn- sentence-start-offset [[first-label & _]]
  (.beginPosition first-label))

(defn- sentence-end-offset [core-labels]
  (.endPosition (nth core-labels (dec (count core-labels)))))

(defn sentence-text [core-labels]
  (mapv #(.get % CoreAnnotations$TextAnnotation) core-labels))

(defn sentenize [text]
  (mapv #(let [start-offset (sentence-start-offset %)
               end-offset (sentence-end-offset %)]
           (array-map :text (subs text start-offset end-offset)
                      :start-offset start-offset
                      :end-offset end-offset))
        (split-sentences text)))


(defprotocol WordProtocol
  "Attempt to convert a given object into a Word, which is used by many downstream algorithms."
  (word [this]))

(extend-protocol ;; WordProtocol
  ;; clojure.lang.PersistentArra
  yMap
  (word [m] (Word. (get m :token)))

  String
  (word [s] (Word. s))

  Word
  (word [w] w)

  Object
  (word [obj] (Word. obj)))

(def ^{:private true}
  load-pos-tagger
  (memoize (fn [] (MaxentTagger. MaxentTagger/DEFAULT_JAR_PATH))))

(defn tag-sentence [sentence]
  ;; FIXME: check load-pos-tagger
  (.tagSentence ^MaxentTagger (load-pos-tagger) ^ArrayList sentence))

(defn tag-words [words]
  (tag-sentence (ArrayList. ^Collection (mapv word words))))

(defprotocol PosTagProtocol
  "Tag a sequence of words with their parts of speech, returning
   a sequence of TaggedWord objects."
  (%pos-tag [this col]))

(extend-protocol PosTagProtocol

  clojure.lang.PersistentArrayMap
  (%pos-tag [_ col] (tag-words ^Collection col))

  CoreLabel
  (%pos-tag [_ sentence] (tag-sentence ^ArrayList sentence))

  String
  (%pos-tag [_ col] (tag-words ^Collection col))

  Character
  (%pos-tag [_ s] (tag-sentence ^ArrayList (tokenize-corelabels ^String s)))

  Object
  (%pos-tag [_ col] (tag-words ^Collection col)))

(defn pos-tag [col]
  (%pos-tag (first col) col))

(defn initialize-pipeline
  "0 Arity: Build NER tagging pipeline; use Stanford model
   1 Arity: Build NER tagging pipeline; use custom model"
  [& [model-path]]
  (let [ner-props (Properties.)]
    (.put ner-props "annotators" "tokenize, ssplit, pos, lemma, ner")
    (when model-path
      ;; Use custom model
      (.put ner-props "ner.model" model-path))
    (StanfordCoreNLP. ner-props true)))
#_
(defn- annotate-text
  "Annotates text tokens with named entity type.
   Returns edu.stanford.nlp.pipeline Annotation object"
  ([pipeline text]
   (.process pipeline text)))

(defn- get-tokens-entities
  "builds map: {:token token :named-entity named-entity}"
  [tok-ann]
  {:token (.get tok-ann CoreAnnotations$TextAnnotation)
   :named-entity (.get tok-ann CoreAnnotations$NamedEntityTagAnnotation)
   :start-offset (.beginPosition tok-ann)
   :end-offset (.endPosition tok-ann)})

#_
(defn- get-token-annotations
  "Passes TokenAnnotations extracted from SentencesAnnotation to get-tokens-entities
  which returns a map {:token token :named-entity ne}"
  [sentence-annotation]
  (mapv get-tokens-entities (.get sentence-annotation CoreAnnotations$TokensAnnotation)))
#_
(defn- get-text-tokens [sen-ann]
  "builds map: {:tokens tokens}"
  {:tokens (get-token-annotations sen-ann)})
#_
(defn- get-sentences-annotation
  "passes SentencesAnnotation extracted from Annotation object to function
  get-text-tokens which returns a map:
  {:tokens {:token token :named-entity ne}}"
  [^Annotation annotation]
  (mapv get-text-tokens (.get annotation CoreAnnotations$SentencesAnnotation)))
#_
(defn tag-ner
  "Returns a map object containing original text, tokens, sentences"
  ([pipeline text] (get-sentences-annotation (annotate-text pipeline text))))

(defn tag-ner
  "Returns a map object containing original text, tokens, sentences"
  [pipeline text]
  (mapv (fn [sen-ann]
          {:tokens (mapv get-tokens-entities (.get sen-ann CoreAnnotations$TokensAnnotation))})
        (.get (.process pipeline text) CoreAnnotations$SentencesAnnotation)))


(let [trf (LabeledScoredTreeReaderFactory.)]

 (defn read-parse-tree [s]
   "Read a parse tree in PTB format from a string (produced by this or another parser)"
   (.readTree
    (.newTreeReader trf
                    (StringReader. s))))

 (defn read-scored-parse-tree [^String s]
   "Read a parse tree in PTB format with scores from a string."
   (read-parse-tree
    (->>
     (filter (fn [^String w]
               (not (and
                     (.startsWith w "[")
                     (.endsWith w "]"))))
             (.split s " "))
     (interpose " ")
     (apply str)))))

(def ^{:private true} load-parser
  (memoize
    (fn []
      (LexicalizedParser/loadModel))))


(defprotocol ParseProtocol
  (parse [this]))

(extend-protocol ParseProtocol

  String
  (parse [s] (parse (tokenize s)))

  Object
  ;;Use the LexicalizedParser to produce a constituent parse of sequence of strings or CoreNLP Word objects.
  (parse [col]
    (.apply ^ParserGrammar (load-parser)
            (ArrayList.
             ^Collection (map word col)))))

(defrecord DependencyParse [words tags edges])

(defn roots [dp]
  (set/difference
   (set (range (count (:words dp))))
   (set (map second (:edges dp)))))

#_
(defn add-roots [dp]
  "Add explicit ROOT relations to the dependency parse. This will turn it from a polytree to a tree."
  (assoc dp :edges
         (concat (:edges dp)
                 (for [r (roots dp)]
                   [-1 r :root]))))

(defn add-roots [dp]
  "Add explicit ROOT relations to the dependency parse. This will turn it from a polytree to a tree."
  (update dp :edges (fn [old-val]
                      (into old-val (mapv #(vector -1 % :root) (roots dp))))))

(defprotocol DependencyParseProtocol
  "Produce a DependencyParse from a sentence, which is a directed graph structure whose nodes are words and edges are typed dependencies (Marneffe et al, 2005) between them."
  (dependency-parse [this]))

(defonce grammatical-structure-factory (.grammaticalStructureFactory (PennTreebankLanguagePack.)))

(extend-protocol DependencyParseProtocol
  LabeledScoredTreeNode
  (dependency-parse [n]
    (try
      (let [ty (.taggedYield n)]
        (DependencyParse.
         (vec (map #(.word ^TaggedWord %) ty))
         (vec (map #(.tag ^TaggedWord %) ty))
         (map (fn [^TypedDependency d]
                [(.. d gov index)
                 (.. d dep index)
                 (keyword
                  (.. d reln toString))])
              (.typedDependencies
               (.newGrammaticalStructure grammatical-structure-factory)))))
      (catch java.lang.RuntimeException _)))

  Object
  (dependency-parse [s] (parse s)))

(defprotocol DependencyGraphProtocol
  (dependency-graph [this]))

(extend-protocol DependencyGraphProtocol
  DependencyParse
  (dependency-graph [dp]
    "Produce a loom graph from a DependencyParse record."
    (let [[words tags edges] (map #(% dp) [:words :tags :edges])
          g (apply graph/digraph (map (partial take 2) edges))]
      (reduce (fn [g [i t]] (attr/add-attr g i :tag t))
              (reduce (fn [g [i w]] (attr/add-attr g i :word w))
                      (reduce (fn [g [gov dep type]]
                                (attr/add-attr g gov dep :type type)) g edges)
                      (map-indexed vector words))
              (map-indexed vector tags))))

  Object
  (dependency-graph [x] (dependency-parse x)))


(defn between [n low high]
  (<= low n high))

(defn -main
  ([]
   (-main 50))
  ([_ arg-max-length & _]
   (-main (Integer/parseInt arg-max-length)))
  ([max-length]
   (let [min-length 5]
     (doseq [line (line-seq (java.io.BufferedReader. *in*))]

       (->> (split-sentences line)
            (filter #(between (count %)
                              min-length
                              max-length))
            (mapv dependency-parse)
            (json/write-str)
            (println))))))

